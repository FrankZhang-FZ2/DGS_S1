---
title: "DGS_S1_analyses"
author: "Qilin Zhang"
date: "2023-02-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###load packages

```{r pac, message = FALSE}
library(summarytools)
library(tidyverse) #data wrangling
library(codebook) #codebook generation
library(future) #reliability
library(ufs) #reliability
library(GGally) #reliability
library(GPArotation) #reliability
library(rio) #reading in different file types
library(labelled) #labeling data
library(psych)
library(corrplot) 
library("psych")
library(mirt)
library(eRm)
library(mice)
library(lavaan)
library(semPlot)
library(parameters)
library(broom)

#if need to download the epmr package
#if (!require("devtools")) install.packages("devtools")   
#devtools::install_github("talbano/epmr")
```

### cleaning


```{r cleaning code, include = FALSE}

## use other read functions as appropriate for file type

dict <- rio::import(file = "data/DGS_S1_dictionary.xlsx") #dictionary

data <- read.csv(file = 'data/DGS_S1_Deidentified For Analyses.csv', sep = ",") #data

data <- data[-c(1:2),-c(1:7)]

## Variable types 
names <- dict %>% 
  filter(type == "character") %>% 
  pull(variable)
data[,names] <- 
  lapply(data[,names], as.character)

names <- dict %>% 
  filter(type == "factor") %>% 
  pull(variable)
data[,names] <- 
  lapply(data[,names], as.numeric) #factor variables are coded as numeric for codebook purposes

names <- dict %>% 
  filter(type == "numeric") %>% 
  pull(variable)
data[,names] <- 
  lapply(data[,names], as.numeric)

rm(names)

##data completion check and imputation

#remove failed attention check -55 participants from this process
data <- data %>%
  filter(DGS_31 == 4) %>%
  filter((DGS_53 == 2))


#function for checking percentage of missing data (unit=%)
percent_missing <- function(x){
  sum(is.na((x))/length(x)*100)
}
missing_R <- apply(data,1,percent_missing)
table(missing_R)

#use if don't want imputation(turn off if I need imputation)
replace_rows <- subset(data, missing_R<=0)
data <- replace_rows
```

```{r imputation}
if(FALSE){
#subset based on filtering criteria
replace_rows <- subset(data, missing_R<=10)
no_rows <- subset(data, missing_R>10)

missing_C <- apply(replace_rows,2,percent_missing)
table(missing_C) #no concern here

replace_data <- replace_rows[,1:85]
leftout <- replace_rows[,86:91]

#check where the NAs are if needed
rindex <- rep(FALSE, nrow(replace_data))
for (i in 1:nrow(replace_data)){
  for (j in 1:grep("DGS_75",colnames(replace_data))){
    if( is.na(replace_data[i,j])){
      rindex[i] = TRUE
      j = ncol(replace_data)+1
    }
  }
}
data_error <- replace_data[rindex,]

rm(data_error)
#imputation
temp <- mice(replace_data)
fixed_data <- complete(temp)  #imputation using mice package
data <- cbind(fixed_data,leftout) #no additional participants were removed

rm(fixed_data,leftout,no_rows,replace_data,replace_rows)
}
```

```{r recode}
##recode

#DGS recode
likert <- dict %>% 
  filter (value_label == "1 = Strongly disagree, 2 = Disagree, 3 = Somewhat disagree, 4 = Neither agree nor disagree, 5 = Somewhat agree, 6 = Agree, 7 = Strongly agree") %>%
  pull(variable)
add_likert <- function(x) {
  val_labels(x) <- c("Strongly disagree"= 1, "Disagree" = 2, "Somewhat disagree" = 3, "Neither agree nor disagree" = 4, "Somewhat agree" = 5, "Agree" = 6, "Strongly agree" = 7) 
  x
}
data <- data %>%
  mutate_at(likert, 
            add_likert)  

rm(likert, add_likert)

#HEXACO_C

likert <- dict %>% 
  filter (value_label == "1 = Strongly disagree, 2 = Somewhat disagree, 3 = Neither agree nor disagree, 4 = Somewhat agree, 5 = Strongly agree") %>%
  pull(variable)
add_likert <- function(x) {
  val_labels(x) <- c("Strongly disagree"= 1, "Somewhat disagree" = 2, "Neither agree nor disagree" = 3, "Somewhat agree" = 4, "Strongly agree" = 5) 
  x
}
data <- data %>%
  mutate_at(likert, 
            add_likert)  

rm(likert, add_likert)

## Reverse-scoring 
reversed_items <- dict %>%  #make a list of reversed items
 filter (keying == -1) %>% 
 pull(variable)

data <- data %>%  #reverse values in data
  mutate_at(reversed_items,
          reverse_labelled_values)

rm(reversed_items)

##scale construction

## Variable labels
var_label(data) <- dict %>% 
  select(variable, label) %>% 
  dict_to_list()

rm(extra)

##DGS
DGS <- dict %>% 
  filter (scale == "DGS") %>% 
  pull(variable)

data$DGS <- data %>% 
  select(all_of(DGS)) %>% 
  aggregate_and_document_scale()

##HEXACO_C

HEXACO_C <- dict %>% 
  filter (scale == "HEXACO_C") %>% 
  pull(variable)

data$HEXACO_C <- data %>% 
  select(all_of(HEXACO_C)) %>% 
  aggregate_and_document_scale()

###7 factors model
M7_1 <- dict %>% 
  filter (factors_7 == 1) %>% 
  pull(variable)
M7_2 <- dict %>% 
  filter (factors_7 == 2) %>% 
  pull(variable)
M7_3 <- dict %>% 
  filter (factors_7 == 3) %>% 
  pull(variable)
M7_4 <- dict %>% 
  filter (factors_7 == 4) %>% 
  pull(variable)
M7_5 <- dict %>% 
  filter (factors_7 == 5) %>% 
  pull(variable)
M7_6 <- dict %>% 
  filter (factors_7 == 6) %>% 
  pull(variable)
M7_7 <- dict %>% 
  filter (factors_7 == 7) %>% 
  pull(variable)

###7 factors model

data$M7_1 <- data %>% 
  select(all_of(M7_1)) %>% 
  aggregate_and_document_scale()

data$M7_2 <- data %>% 
  select(all_of(M7_2)) %>% 
  aggregate_and_document_scale()

data$M7_3 <- data %>% 
  select(all_of(M7_3)) %>% 
  aggregate_and_document_scale()

data$M7_4 <- data %>% 
  select(all_of(M7_4)) %>% 
  aggregate_and_document_scale()

data$M7_5 <- data %>% 
  select(all_of(M7_5)) %>% 
  aggregate_and_document_scale()

data$M7_6 <- data %>% 
  select(all_of(M7_6)) %>% 
  aggregate_and_document_scale()

data$M7_7 <- data %>% 
  select(all_of(M7_7)) %>% 
  aggregate_and_document_scale()

## assumption check
random_variable <- rchisq(nrow(data), 7)
fake_model <- lm(random_variable ~ ., 
                 data = data[ , -c(86:91)])
standardized <- rstudent(fake_model)
fitvalues <- scale(fake_model$fitted.values)
plot(fake_model,2)#check for linearity
#We assume the the multivariate relationship between continuous variables is linear (i.e., no curved)
#There are many ways to test this, but we can use a QQ/PP Plot to examine for linearity

hist(standardized)#check for normality
#We expect that the residuals are normally distributed
#Not that the *sample* is normally distributed 
#Generally, SEM requires a large sample size, thus, buffering against normality deviations

{plot(standardized, fitvalues)
  abline(v = 0)
  abline(h = 0)
}#check for homogeneity + Homoscedasticity
#These assumptions are about equality of the variances
#We assume equal variances between groups for things like t-tests, ANOVA
#Here the assumption is equality in the spread of variance across predicted values 

##rename
data_cleaned <- data

#prepare dataframe for different scales
DGS <- data_cleaned[grep("DGS_1",colnames(data_cleaned)):grep("DGS_75",colnames(data_cleaned))]
DGS <- DGS[,-c(grep("DGS_31",colnames(DGS)),grep("DGS_53",colnames(DGS)))]

HEXACO_C <- data_cleaned[grep("HEXACO_C_1",colnames(data_cleaned)):grep("HEXACO_C_10",colnames(data_cleaned))]
```


# for later use
###Conscientiousness 
Organization <- dict %>% 
  filter (subscale == "Organization") %>% 
  pull(variable)

Diligence <- dict %>% 
  filter (subscale == "Diligence") %>% 
  pull(variable)

Perfectionism <- dict %>% 
  filter (subscale == "Perfectionism") %>% 
  pull(variable)

Prudence <- dict %>% 
  filter (subscale == "Prudence") %>% 
  pull(variable)

###Conscientiousness

data$Organization <- data %>% 
  select(all_of(Organization)) %>% 
  aggregate_and_document_scale()

data$Diligence  <- data %>% 
  select(all_of(Diligence)) %>% 
  aggregate_and_document_scale()

data$Perfectionism <- data %>% 
  select(all_of(Perfectionism)) %>% 
  aggregate_and_document_scale()

data$Prudence <- data %>% 
 select(all_of(Prudence)) %>% 
  aggregate_and_document_scale()




###EFA

```{r EFA_all}
##descriptive analysis for all items
DGS_descriptive <- describe(DGS)
##EFA for DGS

#Kaiser Criterion
ev<- eigen(cor(DGS))
ev$values
sum(ev$values > 1)
sum(ev$values > .7)

#scree plot and parallel analysis
scree(DGS, pc=FALSE)
fa.parallel(DGS,
            fm="ml",
            fa="fa")
```


```{r EFA_9model}
DGS_fit_9 <- DGS %>%
  select(!c(DGS_3,DGS_4,DGS_12,DGS_14,DGS_16,DGS_25,DGS_40,DGS_43,DGS_34,DGS_50,DGS_59,DGS_62,DGS_66,DGS_37,DGS_42,DGS_23))

EFA_fit_9 <- fa(DGS_fit_9,
             nfactors = 9,
             rotate = "oblimin",
             fm="ml")
EFA_fit_9
print(EFA_fit_9$loadings, cutoff = 0.3)
print(EFA_fit_9$loadings)#model Abandoned because of conceptual reasons (see write-up)

```


```{r EFA_7model}
#6 factor (trim items with loading lower than 0.3)

DGS_fit_7 <- DGS %>%
  select(!c(DGS_16,DGS_40,DGS_43,DGS_50,DGS_42,DGS_23,DGS_14))

EFA_fit_7 <- fa(DGS_fit_7,
             nfactors = 7,
             rotate = "oblimin",
             fm="ml")
EFA_fit_7
print(EFA_fit_7$loadings, cutoff = 0.3)
print(EFA_fit_7$loadings)

##fit indices
EFA_fit_7$rms  # Root mean square of the residuals (lower the better)
EFA_fit_7$RMSEA # root mean squared error of approximation (lower the better)
EFA_fit_7$TLI  # tucker lewis index
1- ((EFA_fit_7$STATISTIC-EFA_fit_7$dof)/
      (EFA_fit_7$null.chisq-EFA_fit_7$null.dof))  #CFI

```


```{r EFA_7model}
#7 factors concise model
DGS_fit_7C <- DGS %>%
  select(c(DGS_4,DGS_12,DGS_15,DGS_17,DGS_19,DGS_22,DGS_32,DGS_33,DGS_49,DGS_56,DGS_60,DGS_75,
           DGS_10,DGS_26,DGS_41,DGS_54,DGS_57,DGS_69,DGS_72,
           DGS_9,DGS_27,DGS_29,DGS_46,DGS_51,DGS_52,
           DGS_1,DGS_21,DGS_44,DGS_65,
           DGS_20,DGS_28,DGS_35,DGS_48,DGS_68,
           DGS_6,DGS_38,DGS_39,DGS_45,DGS_67,DGS_70,DGS_71,
           DGS_2,DGS_11,DGS_48,DGS_13))


EFA_fit_7C <- fa(DGS_fit_7C,
             nfactors = 7,
             rotate = "oblimin",
             fm="ml")
EFA_fit_7C
print(EFA_fit_7C$loadings, cutoff = 0.3)
print(EFA_fit_7C$loadings)

##fit indices
EFA_fit_7C$rms  # Root mean square of the residuals (lower the better)
EFA_fit_7C$RMSEA # root mean squared error of approximation (lower the better)
EFA_fit_7C$TLI  # tucker lewis index
1- ((EFA_fit_7C$STATISTIC-EFA_fit_7C$dof)/
      (EFA_fit_7C$null.chisq-EFA_fit_7C$null.dof))  #CFI
```

```{r 7model_trim}
#7 factors model triming
DGS_fit_7C <- DGS %>%
  select(c(DGS_4,DGS_12,DGS_15,DGS_17,DGS_19,DGS_22,DGS_32,DGS_33,DGS_49,DGS_56,DGS_60,DGS_75,
           DGS_10,DGS_26,DGS_41,DGS_54,DGS_57,DGS_69,DGS_72,
           DGS_9,DGS_27,DGS_29,DGS_46,DGS_51,DGS_52,
           DGS_1,DGS_21,DGS_44,DGS_65,
           DGS_20,DGS_28,DGS_35,DGS_68,
           DGS_6,DGS_39,DGS_45,DGS_67,DGS_70,
           DGS_2,DGS_11,DGS_48,DGS_13,DGS_73))
#trim 38,71because of the negative loading on factor 1
#trim 66 because of the low relevancy
#trim 44 because of the repetitiveness in description

EFA_fit_7C <- fa(DGS_fit_7C,
             nfactors = 7,
             rotate = "oblimin",
             fm="ml")
EFA_fit_7C
print(EFA_fit_7C$loadings, cutoff = 0.3)
print(EFA_fit_7C$loadings)

##fit indices
EFA_fit_7C$rms  # Root mean square of the residuals (lower the better)
EFA_fit_7C$RMSEA # root mean squared error of approximation (lower the better)
EFA_fit_7C$TLI  # tucker lewis index
1- ((EFA_fit_7C$STATISTIC-EFA_fit_7C$dof)/
      (EFA_fit_7C$null.chisq-EFA_fit_7C$null.dof))  #CFI
```



###lower structure exploration

```{r lower_structure_F1}

#select items for this factor
DGS_7M_f1 <- DGS%>%
  select(c(DGS_4,DGS_7,DGS_12,DGS_15,DGS_17,DGS_18,DGS_19,DGS_22,DGS_25,DGS_30,DGS_32,DGS_33,DGS_34,DGS_36,DGS_37,DGS_49,DGS_55,DGS_56,DGS_57,DGS_58,DGS_59,DGS_60,DGS_61,DGS_63,DGS_64,DGS_74,DGS_75))

#run for concise model
DGS_7M_f1 <- DGS%>%
  select(c(DGS_4,DGS_12,DGS_15,DGS_17,DGS_19,DGS_22,DGS_32,DGS_33,DGS_49,DGS_56,DGS_60,DGS_75))

cor.plot(DGS_7M_f1)

##Kaiser Criterion
ev<- eigen(cor(DGS_7M_f1))
ev$values
sum(ev$values > 1)
sum(ev$values > .7)

#scree plot and parallel analysis
scree(DGS_7M_f1, pc=FALSE)

fa.parallel(DGS_7M_f1,
            fm="ml",
            fa="fa")
#EFA
EFA_7M_f1 <- fa(DGS_7M_f1,
             nfactors = 3,
             rotate = "oblimin",
             fm="ml")
EFA_7M_f1
print(EFA_7M_f1$loadings, cutoff = 0.3)
print(EFA_7M_f1$loadings)           

#visualization

fa.diagram(EFA_7M_f1)
            
```


```{r lower_structure_F2}

#select items for this factor
DGS_7M_f2 <- DGS%>%
  select(c(DGS_3,DGS_5,DGS_8,DGS_10,DGS_15,DGS_26,DGS_33,DGS_41,DGS_44,DGS_45,DGS_47,DGS_54,DGS_57,DGS_58,DGS_69,DGS_72,DGS_74))
#run for concise model
DGS_7M_f2 <- DGS%>%
  select(c(DGS_10,DGS_26,DGS_41,DGS_54,DGS_57,DGS_69,DGS_72))

cor.plot(DGS_7M_f2)

##Kaiser Criterion
ev<- eigen(cor(DGS_7M_f2))
ev$values
sum(ev$values > 1)
sum(ev$values > .7)

#scree plot and parallel analysis
scree(DGS_7M_f2, pc=FALSE)

fa.parallel(DGS_7M_f2,
            fm="ml",
            fa="fa")
#EFA
EFA_7M_f2 <- fa(DGS_7M_f2,
             nfactors = 1,
             rotate = "oblimin",
             fm="ml")
EFA_7M_f2
print(EFA_7M_f2$loadings, cutoff = 0.3)
print(EFA_7M_f2$loadings)           

#visualization
fa.plot(EFA_7M_f2,
  labels = colnames(DGS_7M_f2)
)

fa.diagram(EFA_7M_f2)
            
```

```{r lower_structure_F3}

#select items for this factor
DGS_7M_f3 <- DGS%>%
  select(c(DGS_9,DGS_27,DGS_29,DGS_46,DGS_51,DGS_52))

#run for concise model
DGS_7M_f3 <- DGS%>%
   select(c(DGS_9,DGS_27,DGS_29,DGS_46,DGS_51,DGS_52))

cor.plot(DGS_7M_f3)

##Kaiser Criterion
ev<- eigen(cor(DGS_7M_f3))
ev$values
sum(ev$values > 1)
sum(ev$values > .7)

#scree plot and parallel analysis
scree(DGS_7M_f3, pc=FALSE)

fa.parallel(DGS_7M_f3,
            fm="ml",
            fa="fa")
#EFA
EFA_7M_f3 <- fa(DGS_7M_f3,
             nfactors = 2,
             rotate = "oblimin",
             fm="ml")
EFA_7M_f3
print(EFA_7M_f3$loadings, cutoff = 0.3) 

EFA_7M_f3 <- fa(DGS_7M_f3,
             nfactors = 1,
             rotate = "oblimin",
             fm="ml")
EFA_7M_f3
print(EFA_7M_f3$loadings, cutoff = 0.3) 
#recommend 1 factor because 2 factors basically separate negative and positive code items.

#visualization
fa.diagram(EFA_7M_f3)
            
```

```{r lower_structure_F4}

#select items for this factor
DGS_7M_f4 <- DGS%>%
  select(c(DGS_1,DGS_21,DGS_44,DGS_63,DGS_65)) #remove 69 due to low loading in the 7 factor model and low conceptual relevancy.

##Kaiser Criterion
ev<- eigen(cor(DGS_7M_f4))
ev$values
sum(ev$values > 1)
sum(ev$values > .7)

#scree plot and parallel analysis
scree(DGS_7M_f4, pc=FALSE)

fa.parallel(DGS_7M_f4,
            fm="ml",
            fa="fa")
#EFA
EFA_7M_f4 <- fa(DGS_7M_f4,
             nfactors = 2,
             rotate = "oblimin",
             fm="ml")
EFA_7M_f4
print(EFA_7M_f4$loadings, cutoff = 0.3) 
#recommend 1 factor becuase these basically separate the negative and positive coded items. 

#visualization
fa.diagram(EFA_7M_f4)

#run for concise model
DGS_7M_f4 <- DGS%>%
   select(c(DGS_1,DGS_21,DGS_44,DGS_65))#recommend 1 factor for the concise version

cor.plot(DGS_7M_f4)

##Kaiser Criterion
ev<- eigen(cor(DGS_7M_f4))
ev$values
sum(ev$values > 1)
sum(ev$values > .7)

#scree plot and parallel analysis
scree(DGS_7M_f4, pc=FALSE)

fa.parallel(DGS_7M_f4,
            fm="ml",
            fa="fa")
#EFA
EFA_7M_f4 <- fa(DGS_7M_f4,
             nfactors = 1,
             rotate = "oblimin",
             fm="ml")
EFA_7M_f4
print(EFA_7M_f4$loadings, cutoff = 0.3) 
#recommend 1 factor 

#visualization
fa.diagram(EFA_7M_f4)
            
```

```{r lower_structure_F5}

#select items for this factor
DGS_7M_f5 <- DGS%>%
  select(c(DGS_20,DGS_24,DGS_28,DGS_35,DGS_48,DGS_64,DGS_68)) #remove 47 due to low loading in the 7 factor model and low conceptual relevancy.

#run for concise model
DGS_7M_f5 <- DGS%>%
   select(c(DGS_20,DGS_28,DGS_35,DGS_48,DGS_68)) # recommend one factor for the concise version

cor.plot(DGS_7M_f5)

##Kaiser Criterion
ev<- eigen(cor(DGS_7M_f5))
ev$values
sum(ev$values > 1)
sum(ev$values > .7)

#scree plot and parallel analysis
scree(DGS_7M_f5, pc=FALSE)

fa.parallel(DGS_7M_f5,
            fm="ml",
            fa="fa")
#EFA
EFA_7M_f5 <- fa(DGS_7M_f5,
             nfactors = 2,
             rotate = "oblimin",
             fm="ml")
EFA_7M_f5
print(EFA_7M_f5$loadings, cutoff = 0.3) 
#2 factors model looks good. It seperate cognitive and affective components

#visualization
fa.diagram(EFA_7M_f5)
            
```

```{r lower_structure_F6}

#select items for this factor
DGS_7M_f6 <- DGS%>%
  select(c(DGS_6,DGS_18,DGS_38,DGS_39,DGS_45,DGS_55,DGS_67,DGS_70,DGS_71)) #remove 62 due to low loading in the 7 factor model and low conceptual relevancy.

#run for concise model
DGS_7M_f6 <- DGS%>%
   select(c(DGS_6,DGS_38,DGS_39,DGS_45,DGS_67,DGS_70,DGS_71)) # need further inspection

cor.plot(DGS_7M_f6)

##Kaiser Criterion
ev<- eigen(cor(DGS_7M_f6))
ev$values
sum(ev$values > 1)
sum(ev$values > .7)

#scree plot and parallel analysis
scree(DGS_7M_f6, pc=FALSE)

fa.parallel(DGS_7M_f6,
            fm="ml",
            fa="fa")
#EFA
EFA_7M_f6 <- fa(DGS_7M_f6,
             nfactors = 3,
             rotate = "oblimin",
             fm="ml")
EFA_7M_f6 
print(EFA_7M_f6 $loadings, cutoff = 0.3) 

EFA_7M_f6 <- fa(DGS_7M_f6,
             nfactors = 2,
             rotate = "oblimin",
             fm="ml")
EFA_7M_f6 
print(EFA_7M_f6 $loadings, cutoff = 0.3)

##need to check 38 and 71 and see if they fit the model. IRT may be helpful here.
DGS%>%
  ggplot()+
  geom_bar(aes(x=DGS_38, alpha = 0.1))+
  geom_bar(aes(x=DGS_67))
#visualization
fa.diagram(EFA_7M_f6)
            
```

```{r lower_structure_F7}

#select items for this factor
DGS_7M_f7 <- DGS%>%
  select(c(DGS_2,DGS_5,DGS_11,DGS_13,DGS_48,DGS_66,DGS_73)) #remove 47 due to low loading in the 7 factor model and low conceptual relevancy.

#run for concise model
DGS_7M_f7 <- DGS%>%
   select(c(DGS_2,DGS_11,DGS_13,DGS_48,DGS_73)) # recommend one factor for the concise version

cor.plot(DGS_7M_f7)

##Kaiser Criterion
ev<- eigen(cor(DGS_7M_f7))
ev$values
sum(ev$values > 1)
sum(ev$values > .7)

#scree plot and parallel analysis
scree(DGS_7M_f7, pc=FALSE)

fa.parallel(DGS_7M_f7,
            fm="ml",
            fa="fa")
#EFA
EFA_7M_f7 <- fa(DGS_7M_f7,
             nfactors = 1,
             rotate = "oblimin",
             fm="ml")
EFA_7M_f7
print(EFA_7M_f7$loadings, cutoff = 0.3) 

DGS%>%
  ggplot()+
  geom_bar(aes(x=DGS_2, alpha = 0.1))+
  geom_bar(aes(x=DGS_11))
#visualization
fa.diagram(EFA_7M_f7)
            
```


###Confirmatory factor analysis

```{r CFA}

DGS_7M_model <- '
F1 =~ DGS_4+DGS_7+DGS_12+DGS_15+DGS_17+DGS_18+DGS_19+DGS_22+DGS_25+DGS_30+DGS_32+DGS_33+DGS_34+DGS_36+DGS_37+DGS_49+DGS_55+DGS_56+DGS_57+DGS_58+DGS_59+DGS_60+DGS_61+DGS_63+DGS_64+DGS_74+DGS_75
F2 =~ DGS_3+DGS_5+DGS_8+DGS_10+DGS_15+DGS_26+DGS_33+DGS_41+DGS_44+DGS_45+DGS_47+DGS_54+DGS_57+DGS_58+DGS_69+DGS_72+DGS_74
F3 =~ DGS_9+DGS_27+DGS_29+DGS_46+DGS_51+DGS_52
F4 =~ DGS_1+DGS_21+DGS_44+DGS_63+DGS_65
F5 =~ DGS_20+DGS_24+DGS_28+DGS_35+DGS_48+DGS_64+DGS_68
F6 =~ DGS_6+DGS_18+DGS_38+DGS_39+DGS_45+DGS_55+DGS_67+DGS_70+DGS_71
F7 =~ DGS_2+DGS_5+DGS_11+DGS_13+DGS_48+DGS_66+DGS_73
'

DGS_7M_fit <- cfa(
  model = DGS_7M_model,
  data = DGS,
  std.lv = TRUE)

summary(DGS_7M_fit,
        standardized = TRUE,
        rsquare = TRUE,
        fit.measures=TRUE)

parameterestimates(DGS_7M_fit,
                   standardized = TRUE)

fitmeasures(DGS_7M_fit)

modificationindices(DGS_7M_fit,sort = T)

semPaths(DGS_7M_fit,
         whatLabels = "std",
         what = "std",
         layout = "tree2",
         edge.label.cex = 1)

model_parameters(DGS_7M_fit, standardize = TRUE)

```


```{r CFA}
##CFA

#factor construction
DGS_7M_ML1 <- DGS_fit%>%
  select(c(DGS_17,DGS_22,DGS_36,DGS_58,DGS_60,DGS_61))
DGS_7M_ML2 <- DGS_fit %>%
  select(c(DGS_24,DGS_28,DGS_35,DGS_68))
DGS_7M_ML3 <- DGS_fit %>%
  select(c(DGS_45,DGS_67,DGS_70))
DGS_7M_ML4 <- DGS_fit %>%
  select(c(DGS_1,DGS_21,DGS_44,DGS_65))
DGS_7M_ML5 <- DGS_fit %>%
  select(c(DGS_3,DGS_10,DGS_26,DGS_41,DGS_47,DGS_54,DGS_69,DGS_72))
DGS_7M_ML6 <- DGS_fit %>%
  select(c(DGS_9,DGS_27,DGS_29,DGS_46,DGS_51,DGS_52))
DGS_7M_ML7 <- DGS_fit %>%
  select(c(DGS_6,DGS_37,DGS_39,DGS_49,DGS_59,DGS_64))

DGS_7M <- c(DGS_7M_ML1,DGS_7M_ML2,DGS_7M_ML3,DGS_7M_ML4,DGS_7M_ML5,DGS_7M_ML6,DGS_7M_ML7)

DGS_6M_model <- '
#F1 =~ DGS_4+DGS_12+DGS_15+DGS_17+DGS_18+DGS_19+DGS_30+DGS_32+DGS_33+DGS_36+DGS_49+DGS_56+DGS_57+DGS_58+DGS_60+DGS_61+DGS_63+DGS_74

F1_1 =~ DGS_15+DGS_17+DGS_30+DGS_33+DGS_57+DGS_58+DGS_61+DGS_63+DGS_74
F1_2 =~ DGS_18+DGS_19+DGS_32+DGS_36+DGS_49+DGS_56+DGS_60
F1_3 =~ a*DGS_4+a*DGS_12
F1 =~ F1_1+F1_2+F1_3
F5 =~ DGS_5+DGS_10+DGS_26+DGS_41+DGS_47+DGS_54+DGS_69+DGS_72+DGS_44
F6 =~ DGS_1+DGS_21+DGS_44+DGS_65
FG1 =~ F5+F6
F4 =~ DGS_9+DGS_27+DGS_29+DGS_46
F2 =~ DGS_28+DGS_35+DGS_48+DGS_68
F3 =~ DGS_38+DGS_39+DGS_67+DGS_70
FG2 =~ F2+F3
FM1 =~ F1+FG1+FG2+F4
'

DGS_6M_fit <- cfa(
  model = DGS_6M_model,
  data = DGS,
  std.lv = TRUE)

summary(DGS_6M_fit,
        standardized = TRUE,
        rsquare = TRUE,
        fit.measures=TRUE)

parameterestimates(DGS_6M_fit,
                   standardized = TRUE)

fitmeasures(DGS_6M_fit)

modificationindices(DGS_6M_fit,sort = T)

semPaths(DGS_6M_fit,
         whatLabels = "std",
         what = "std",
         layout = "tree2",
         edge.label.cex = 1)

model_parameters(DGS_7M_ML1_fit, standardize = TRUE)

tidy(DGS_7M_ML1_fit) #with corvar compared to the latter one
glance(DGS_7M_ML1_fit,)  # fit indices in a glance

#compare model: anova(model1,model2)
#check fitmeasures(model, c("aic","evic"))


##Reliability
factanal(as.matrix(DGS_7M_ML1), factors =1, rotation = "promax")

factanal(as.matrix(DGS_7M_ML6), factors =2, rotation = "promax")

#visualization

DGS_6M_ML4 <- DGS %>%
  select(c(DGS_9,DGS_27,DGS_29,DGS_46,DGS_52))
corrplot(cor(DGS_6M_ML4))

DGS_6M_ML3 <- DGS %>%
  select(c(DGS_38,DGS_39,DGS_67,DGS_70))
corrplot(cor(DGS_6M_ML3))


## make a correlation matrix to screen for overlapping items
## Pick out 

##we can use corplot
#corrplot(cor(data_cleaned[,-c(86:91)]))
```


```{r}
DGS_test <- '
C1 =~ DGS_45+DGS_67+DGS_70
C2 =~ DGS_38+DGS_71+DGS_70
C3 =~ DGS_6+DGS_19+DGS_39+DGS_55+DGS_67

C =~C1+C2+C3
'

DGS_tes_fit <- cfa(
  model = DGS_test,
  data = DGS,
  std.lv = TRUE)

summary(DGS_tes_fit,
        standardized = TRUE,
        rsquare = TRUE,
        fit.measures=TRUE)

modificationindices(DGS_tes_fit,sort = T)

semPaths(DGS_tes_fit,
         whatLabels = "std",
         what = "std",
         layout = "tree2",
         edge.label.cex = 1)

```



###Item analysis

```{r Item_analysis}

describe(DGS)

data_cleaned %>%
  select(DGS_1) %>%
  ggplot(aes(x=DGS_1)) +
  geom_bar()

data_cleaned %>%
  select(DGS_12) %>%
  ggplot(aes(x=DGS_12)) +
  geom_bar()

data_cleaned %>%
  select(DGS_15) %>%
  ggplot(aes(x=DGS_15)) +
  geom_bar()

data_cleaned %>%
  select(DGS_17) %>%
  ggplot(aes(x=DGS_17)) +
  geom_bar()

##make these into a function? 
  test <- DGS_7M_f7-1
  RSM_test <- RSM(X = test)
  person.parameter_test <- person.parameter(object = RSM_test)
  itemfit_test <- itemfit(object = person.parameter_test)
  thresholds_test <- thresholds(object = RSM_test)
  
  ?RSM



## functions for Rating Scale Model
IRT_R <- function(x) {
  M <- x-1
  RSM_M <- RSM(X = M)
  person.parameter_M <- person.parameter(object = RSM_M)
  itemfit_M <- itemfit(object = person.parameter_M)
  thresholds_M <- thresholds(object = RSM_M)
  return(itemfit_M)
}

IRT_R(temp)


temp <- DGS_7M_f4 %>%
  select(!c(DGS_21,DGS_65))

IRT_R_G <- function(x) {
  M <- x-1
  RSM_M <- RSM(X = M)
  person.parameter_M <- person.parameter(object = RSM_M)
  itemfit_M <- itemfit(object = person.parameter_M)
  thresholds_M <- thresholds(object = RSM_M)
  plotICC(object = RSM_M)
}

IRT_R_G(DGS_7M_f4)

M7_f6 <- DGS%>%
  select(DGS_45,DGS_67,DGS_70)

M7_f5 <- DGS%>%
  select(DGS_2,DGS_11,DGS_70)


IRT_R(DGS)


M<- M7_f6-1

RSM_M <- RSM(X = M)

person.parameter_M <- person.parameter(object = RSM_M)

itemfit_M <- itemfit(object = person.parameter_M)

itemfit_M

thresholds_M <- thresholds(object = RSM_M)

thresholds_M 

v_threshpar <- thresholds_M$threshpar[1:2]
plotICC(object = RSM_M)
abline(v=v_threshpar,
       col = "gray")

M<- M7_f5-1

RSM_M <- RSM(X = M)

person.parameter_M <- person.parameter(object = RSM_M)

itemfit_M <- itemfit(object = person.parameter_M)

itemfit_M

thresholds_M <- thresholds(object = RSM_M)

thresholds_M 

v_threshpar <- thresholds_M$threshpar[1:2]
plotICC(object = RSM_M)
abline(v=v_threshpar,
       col = "gray")

##create the item information curve

```


```{r scale_scoring}

DGS_7C_1 <- DGS %>%
  select(c(DGS_4,DGS_12,DGS_15,DGS_17,DGS_19,DGS_22,DGS_32,DGS_33,DGS_49,DGS_56,DGS_60,DGS_75))
data$DGS_7C_1 <- rowSums(DGS_7C_1)/ncol(DGS_7C_1)
data %>%
  ggplot(aes(x= DGS_7C_1))+
  geom_density()

DGS_7C_2 <- DGS %>%
  select(c(DGS_10,DGS_26,DGS_41,DGS_54,DGS_57,DGS_69,DGS_72))
data$DGS_7C_2 <- rowSums(DGS_7C_2)/ncol(DGS_7C_2)
data %>%
  ggplot(aes(x= DGS_7C_2))+
  geom_density()

DGS_7C_3 <- DGS %>%
  select(c(DGS_9,DGS_27,DGS_29,DGS_46,DGS_51,DGS_52))
data$DGS_7C_3 <- rowSums(DGS_7C_3)/ncol(DGS_7C_3)
data %>%
  ggplot(aes(x= DGS_7C_3))+
  geom_density()


DGS_7C_4 <- DGS %>%
  select(c(DGS_1,DGS_21,DGS_44,DGS_65))
data$DGS_7C_4 <- rowSums(DGS_7C_4)/ncol(DGS_7C_4)

data %>%
  ggplot(aes(x= DGS_7C_4))+
  geom_density()


DGS_7C_5 <- DGS %>%
  select(c(DGS_20,DGS_28,DGS_35,DGS_48,DGS_68))
data$DGS_7C_5<- rowSums(DGS_7C_5)/ncol(DGS_7C_5)

data %>%
  ggplot(aes(x= DGS_7C_5))+
  geom_density()


DGS_7C_6 <- DGS %>%
  select(c(DGS_6,DGS_38,DGS_39,DGS_45,DGS_67,DGS_70,DGS_71))
data$DGS_7C_6 <- rowSums(DGS_7C_6)/ncol(DGS_7C_6)

data %>%
  ggplot(aes(x= DGS_7C_6))+
  geom_density()


DGS_7C_7 <- DGS %>%
  select(c(DGS_2,DGS_11,DGS_48,DGS_13))
data$DGS_7C_7 <- rowSums(DGS_7C_7)/ncol(DGS_7C_7)

data %>%
  ggplot(aes(x= DGS_7C_7))+
  geom_density()


```
```{r analysis}
psych::omega(HEXACO_C, nfactors = 2)

DGS_HEXACO <- data %>%
  select(c(HEXACO_C,starts_with("DGS_7C_")))

cor.plot(DGS_HEXACO)
```

###Code Book

```{r codebook}
#codebook_data <- data %>% #select only the variables to display for codebook
#select(-ID)

metadata(data)$name <- "A short name for the data"
metadata(data)$description <- "Longer description of the dataset"
metadata(data)$temporalCoverage <- "Tdataspan of data collection" 

codebook(data, metadata_json = F, metadata_table = F) #generate codebook, excluding some messy meta-data
```